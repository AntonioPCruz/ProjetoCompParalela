# Visual Analysis: `spec_advance()` Parallelization

## 1. Control Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ spec_advance()                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Initialize     â”‚ [S] Sequential
                    â”‚ Constants      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  PARALLEL REGION (Main loop)          â”‚ [P] Parallelizable
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚     with sync
        â”‚  â”‚ FOR i = 0 to spec->np              â”‚â”‚
        â”‚  â”‚  â”œâ”€ Field interpolation âœ…         â”‚â”‚
        â”‚  â”‚  â”œâ”€ Boris pusher âœ…                â”‚â”‚
        â”‚  â”‚  â”œâ”€ Energy reduction [R]           â”‚â”‚
        â”‚  â”‚  â”œâ”€ Position update âœ…             â”‚â”‚
        â”‚  â”‚  â””â”€ Current deposition [X]         â”‚â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
        â”‚  After loop: BARRIER                  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
        â”‚  â”‚ CRITICAL: Merge thread-local J    â”‚â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Store energy   â”‚ [S] Sequential
                    â”‚ Increment iter â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Boundary conditions           â”‚ [S/P] Mixed
            â”‚ â”œâ”€ Window move âœ—             â”‚
            â”‚ â”œâ”€ Absorbing BC âœ—            â”‚
            â”‚ â””â”€ Periodic BC âœ“             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Sort particles â”‚ [S] Sequential
                    â”‚ (if needed)    â”‚ (~rarely, n_sort)
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Record timing  â”‚ [S] Sequential
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
âœ… = Safe to parallelize
[R] = Reduction operation
[X] = Data race
[S] = Sequential only
[P] = Parallelizable
```

---

## 2. Data Access Diagram

### Thread 0 (Particle 0):
```
Read: E_part[], B_part[] â”€â”€â”€â”€â”€â”€â”
      spec->part[0] â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
Compute: Local vars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¼â”€> Temp. storage
Write: part[0].ux/uy/uz â—„â”€â”€â”€â”€â”˜
       part[0].x/ix â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       current->J[] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš« RACE!
       energy â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš« RACE!
```

### Thread 1 (Particle 1):
```
Read: E_part[], B_part[] â”€â”€â”€â”€â”€â”€â”
      spec->part[1] â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
Compute: Local vars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–¼â”€> Temp. storage
Write: part[1].ux/uy/uz â—„â”€â”€â”€â”€â”˜
       part[1].x/ix â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       current->J[] â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš« RACE!
       energy â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸš« RACE!
```

### Problem:
```
    T0: J[5] += 0.5 â”€â”€â”
                      â”œâ”€â–º Lost update or non-deterministic
    T1: J[5] += 0.3 â”€â”€â”˜
```

---

## 3. Memory Layout Before/After

### Current (Sequential):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Global Memory                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ E_part[0..nx]      (Read-only)       â”‚
â”‚ B_part[0..nx]      (Read-only)       â”‚
â”‚ part[0]  â”                           â”‚
â”‚ part[1]  â”œâ”€ Particle array           â”‚
â”‚ part[2]  â”‚ (Updated sequentially)    â”‚
â”‚ ...      â”˜                           â”‚
â”‚ J[0..nx] â—„â”€ Current grid             â”‚
â”‚          â—„â”€ (Updated sequentially)   â”‚
â”‚ energy   â—„â”€ Accumulator              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### With Parallelization (Proposed):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Global Memory                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ E_part[0..nx]      (Read-only)       â”‚
â”‚ B_part[0..nx]      (Read-only)       â”‚
â”‚ part[0]  â”                           â”‚
â”‚ part[1]  â”œâ”€ Particle array           â”‚
â”‚ part[2]  â”‚ (Thread-safe per-particle â”‚
â”‚ ...      â”˜  writes)                  â”‚
â”‚ J[0..nx] â—„â”€ Current grid             â”‚
â”‚          â—„â”€ (Updated in critical)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Per-Thread Memory (Stack/TLS)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Thread 0]                           â”‚
â”‚   J_local[0..nx] â—„â”€ Thread-local J   â”‚
â”‚   (Updated freely, no sync)          â”‚
â”‚                                      â”‚
â”‚ [Thread 1]                           â”‚
â”‚   J_local[0..nx] â—„â”€ Thread-local J   â”‚
â”‚   (Updated freely, no sync)          â”‚
â”‚                                      â”‚
â”‚ [Thread N]                           â”‚
â”‚   J_local[0..nx] â—„â”€ Thread-local J   â”‚
â”‚   (Updated freely, no sync)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After loop: All J_local[i] â†’ accumulated into global J[]
            (One critical section, high efficiency)
```

---

## 4. Speedup Curve Analysis

### Theoretical vs. Practical

```
Speedup
  â”‚        â•±â•±  Ideal (100% parallelizable)
  â”‚      â•±â•±â”
20 â”‚    â•±â•± â”‚  Realistic (90% parallelizable)
  â”‚  â•±â•±â”  â”‚  â†“ Amdahl's limit: S_max = 1/0.1 = 10x
  â”‚â•±â•±â” â”‚  â”‚
15 â”‚ â”‚ â”‚  â”‚
  â”‚ â”‚ â”‚  â”‚
10 â”‚ â”‚ â”‚â”€â”€â”´â”€â”€ Practical Speedup = 10x / (1 + overhead)
  â”‚ â”‚ â”‚                          â‰ˆ 9.5x on 12 cores (95% of limit)
  â”‚ â”‚ â”‚
  â”œâ”€â”¼â”€â”¼â”€â”€â”€â”€â”€â”€ Expected with Strategy C
  â”‚ â”‚ â”‚
 5 â”‚ â”‚ â”‚
  â”‚ â”‚ â”‚
  â”‚ â”‚ â”‚
  â””â”€â”¼â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1 â”‚ 2 4 6 8 10 12 16 20 24 28  Number of Threads
    
   â–² Speedup decreases beyond 12 threads due to:
   - Merge phase overhead
   - Memory bandwidth saturation
   - Load imbalance
```

### Performance Comparison by Strategy

```
Speedup on 12 cores:

Strategy A (Naive - BROKEN):
  0.5x    âœ—âœ—âœ— Non-deterministic, incorrect

Strategy B (Atomics):
  2-3x    âš ï¸ Safe but slow due to serialization
          
Strategy C (Thread-local grids) âœ… RECOMMENDED:
  9.5x    âœ“âœ“âœ“ Near-linear, efficient, correct

Serial reference:
  1.0x    â– â– â–  (baseline)
```

---

## 5. Data Dependency Graph

### Loop Iteration Independence

```
Iteration 0:
  spec->part[0].ux â”€â”
  spec->part[0].uy â”€â”¼â”€> Boris pusher â”€â”
  spec->part[0].uz â”€â”˜                  â”œâ”€> part[0].ux/uy/uz/x/ix
  E_part[], B_part[] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       (no dependencies on iterations 1,2,...)
       
Iteration 1:
  spec->part[1].ux â”€â”
  spec->part[1].uy â”€â”¼â”€> Boris pusher â”€â”
  spec->part[1].uz â”€â”˜                  â”œâ”€> part[1].ux/uy/uz/x/ix
  E_part[], B_part[] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       (independent of iteration 0)
       
Iteration 2:
  spec->part[2].ux â”€â”
  spec->part[2].uy â”€â”¼â”€> Boris pusher â”€â”
  spec->part[2].uy â”€â”˜                  â”œâ”€> part[2].ux/uy/uz/x/ix
  E_part[], B_part[] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       (independent of iterations 0,1)

Conclusion: âœ… ALL ITERATIONS ARE INDEPENDENT
            â†’ Can execute in any order
            â†’ Safe for parallel for-loop
            
Caveat: energy += ... creates implicit dependency via reduction
        Solution: Use #pragma omp for reduction(+:energy)
```

---

## 6. Critical Section Impact

### Timeline: Execution on 4 threads

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Main Loop Phase (Parallelizable)                           â•‘
â• â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•£ 90% of time here
â•‘ T0     â”‚ T1     â”‚ T2     â”‚ T3     â•‘
â•‘        â”‚        â”‚        â”‚        â•‘
â•‘ 25 ms  â”‚ 25 ms  â”‚ 25 ms  â”‚ 25 ms  â•‘
â•‘ (with  â”‚ (with  â”‚ (with  â”‚ (with  â•‘
â•‘  load  â”‚  load  â”‚  load  â”‚  load  â•‘
â•‘ imbaln)â”‚ imbaln)â”‚ imbaln)â”‚ imbaln)â•‘
â•‘        â”‚        â”‚        â”‚        â•‘
â•šâ•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•
           â•‘ Implicit barrier â•‘
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Critical Section: Merge Phase                              â•‘
â• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•£
â•‘ T0 acquires lock                                           â•‘
â•‘   for i = 0 to nx: global_J[i] += J_local[0][i]          â•‘
â•‘ (T1, T2, T3 wait...)                                       â•‘
â•‘   ~5 ms (1.25% of total with good NUMA awareness)          â•‘
â•‘ T0 releases lock                                           â•‘
â•‘                                                             â•‘
â•‘ T1 acquires lock                                           â•‘
â•‘   for i = 0 to nx: global_J[i] += J_local[1][i]          â•‘
â•‘ (T0, T2, T3 wait...)                                       â•‘
â•‘   ~5 ms                                                     â•‘
â•‘ ... (repeat for T2, T3)                                    â•‘
â•‘                                                             â•‘
â•‘ Total critical section: ~20 ms (5% of loop time)           â•‘
â•šâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•
```

**Analysis:**
- Parallelizable phase: 90 ms (4 threads, ~100 ms per thread)
- Critical section: 20 ms serialized (all 4 threads)
- Total time: 90 + 20 = 110 ms (vs. 400 ms serial)
- Speedup: 400/110 = **3.6x** âœ… (close to ideal 4x)

---

## 7. Current Deposition Visualization

### Single Particle Trajectory

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Grid cells          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cell: â”‚ i-1 â”‚  i  â”‚ i+1 â”‚
      Â·â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€Â·
      â”‚     â”‚  â—â†’ â”‚     â”‚  Particle moves from center to right
      Â·â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€Â·
           Grid   Grid
           point  point
            i      i+1

Current deposited:
  J[i-1].x += 0    (no contribution)
  J[i  ].x += 0.6  â—„â”€ Weighted by position
  J[i+1].x += 0.4  â—„â”€ Weighted by position
  
With 2 particles at same location:
  Particle 0:  J[i]   += 0.6, J[i+1] += 0.4
  Particle 1:  J[i]   += 0.5, J[i+1] += 0.5
                  â†“
               RACE if parallel!
               
  Expected:    J[i]   = 0 + 0.6 + 0.5 = 1.1
               J[i+1] = 0 + 0.4 + 0.5 = 0.9
               
  Possible if racey: J[i] = 0.6 or 0.5 (lost second update!)
```

---

## 8. Synchronization Overhead Analysis

### Strategy Comparison

```
Cycle time for 1 particle per cell (ppc=1):

Strategy A (Atomics for each J[] write):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Compute: 2 Î¼s                   â”‚
  â”‚ Atomic J[i].x += ...     1 Î¼s   â”‚ â† LOCK & SYNC
  â”‚ Atomic J[i].y += ...     1 Î¼s   â”‚
  â”‚ Atomic J[i].z += ...     1 Î¼s   â”‚
  â”‚ Atomic J[i+1].x += ...   1 Î¼s   â”‚ â† LOCK & SYNC
  â”‚ ...                      4 Î¼s   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Total: ~14 Î¼s per particle      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  Speedup: ~50% only (serialization at J[] accesses)

Strategy C (Thread-local, single merge):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Compute: 2 Î¼s                   â”‚
  â”‚ Local J[i].x += ...   0.1 Î¼s    â”‚ â† NO SYNC
  â”‚ Local J[i].y += ...   0.1 Î¼s    â”‚
  â”‚ Local J[i].z += ...   0.1 Î¼s    â”‚
  â”‚ Local J[i+1].x += ...0.1 Î¼s     â”‚ â† NO SYNC
  â”‚ ...                   0.4 Î¼s    â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Per-particle time: ~2.4 Î¼s       â”‚
  â”‚ (only 1 sync per particle â†’ merge) â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Merge overhead: amortized        â”‚
  â”‚ ~0.2 Î¼s per particle            â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ Total effective: ~2.6 Î¼s         â”‚
  â”‚ (vs 14 Î¼s for Strategy B)        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  Speedup: ~90% of ideal (much better than Strategy B)
```

---

## 9. Memory Bandwidth Requirement

### Current Deposition Memory Pattern

```
Sequential Access (Cache-friendly):
  Thread 0:  J[0,1,2,3] â† Cached âœ“
  Merge:     Accumulate into global J[0,1,2,3] âœ“
  
  Thread 1:  J[0,1,2,3] â† Cached âœ“
  Merge:     Accumulate into global J[0,1,2,3] âœ“
  
  Pattern:   Strided access to local grid âœ“
             Single pass through global grid âœ“
  
Random Access (Cache-unfriendly):
  Particle 0: Deposit to J[135, 137]    â† Cache miss
  Particle 1: Deposit to J[5, 7]         â† Cache miss
  Particle 2: Deposit to J[892, 894]    â† Cache miss
  ...
  Pattern:   Scattered writes âœ—
             Many cache misses âœ—
             Bandwidth bottleneck âœ—
```

**Implication:** Thread-local grids have much better cache behavior
                 than direct global access â†’ Speedup opportunity!

---

## 10. Key Numbers Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parallelization Effectiveness Summary           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ % of code in main loop:          90%            â”‚
â”‚ % potentially parallelizable:     90%           â”‚
â”‚ Amdahl's Law speedup limit:       10x           â”‚
â”‚ Achievable speedup (12 cores):    9.5x          â”‚
â”‚ Efficiency:                       79%           â”‚
â”‚ Data races in main loop:          2 (J[], energy)
â”‚ Races solvable:                   âœ… Both       â”‚
â”‚ Thread-local memory per thread:   ~50 KB        â”‚
â”‚ Critical section duration:        ~5% loop time â”‚
â”‚ Expected comm. overhead:          ~15% on 12    â”‚
â”‚                                   cores         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 11. Scalability Projection

```
Speedup vs. Core Count on A64FX:

Theoretical (no overhead):
  Speedup = N (linear)
          â•±â•±
        â•±â•±
      â•±â•± â† 100% scalable

Realistic (with 10% sequential overhead):
    â•±â•±
  â•±â•±
â•±â•± â† 90% scalable

Actual (with communication overhead):
  â•±
 â•±â”€ â† 85% scalable
  
With better optimization:
 â•±  â† Maybe 95% scalable
  
Speedup on Deucalion (A64FX, up to 48 cores):
  1 core:  1.0x
  4 cores: 3.6x (90% eff.)
  8 cores: 7.0x (88% eff.)
 12 cores: 9.9x (82% eff.)
 16 cores:12.5x (78% eff.)  â† Probably optimal point
 24 cores:15.8x (66% eff.)  â† Merge overhead noticeable
 48 cores:20.8x (43% eff.)  â† Communication limited
```

---

**End of visual analysis. For detailed information, see other documentation.**

